<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scan to Reveal</title>

    <meta name="apple-itunes-app" content="app-id=6499342348, app-clip-bundle-id=com.alivenow.scanreveal.srappclip, app-clip-display=card"/>
    <meta name="apple-itunes-app-clip-bundle-id" content="com.alivenow.scanreveal.srappclip" />
    <meta name="apple-itunes-app-clip-app-banner" content="yes" />
   <style>
      body {
        font-family: monospace;
        margin: 0;
        overflow: hidden;
        position: fixed;
        width: 100%;
        height: 100vh;
        -webkit-user-select: none;
        user-select: none;
      }
      #info {
        position: absolute;
        left: 50%;
        bottom: 0;
        transform: translate(-50%, 0);
        margin: 1em;
        z-index: 10;
        display: block;
        width: 100%;
        line-height: 2em;
        text-align: center;
      }
      #info * {
        color: #fff;
      }
      .title {
        background-color: rgba(40, 40, 40, 0.4);
        padding: 0.4em 0.6em;
        border-radius: 0.1em;
      }
      .links {
        background-color: rgba(40, 40, 40, 0.6);
        padding: 0.4em 0.6em;
        border-radius: 0.1em;
      }
      canvas {
        position: absolute;
        top: 0;
        left: 0;
      }
    </style>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js"
        		integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
		<script>
		        $(document).ready(function () {
		
		            // const urlParams = new URLSearchParams(window.location.search)
		
		            // const oidValue = urlParams.get('oid')
		            // const cidValue = urlParams.get('cid')
		
		            // posthog.capture('QR_SCANNED', {
		            //     oid: oidValue,
		            //     cid: cidValue
		            // })
		
		            // if (oidValue != null && oidValue.length > 0) {
		            //     if (navigator.userAgent.toLowerCase().indexOf("android") > -1) {
		            //         window.location.href = 'https://play.google.com/store/apps/details?id=com.flam.instant&launch=true&oid=' + oidValue
		            //         $("#mobile-redirect").show()
		            //     }
		            // } else {
		            //     if (navigator.userAgent.toLowerCase().indexOf("android") > -1) {
		            //         window.location.href = 'https://play.google.com/store/apps/details?id=com.flam.instant&launch=true&cid=' + cidValue
		            //         $("#mobile-redirect").show()
		            //     }
		            // }
		
		
		            // else if(navigator.userAgent.toLowerCase().indexOf("iphone") > -1){
		            //          window.location.href = 'https://apps.apple.com/us/app/live-portrait/id946640611';
		            //          $("#mobile-redirect").show()
		            //  } else {
		            //         $("#desktop-message").show()
		            //  }
		        });
		</script>
		<script>
			!function(t,e){var o,n,p,r;e.__SV||(window.posthog=e,e._i=[],e.init=function(i,s,a){function g(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(p=t.createElement("script")).type="text/javascript",p.async=!0,p.src=s.api_host+"/static/array.js",(r=t.getElementsByTagName("script")[0]).parentNode.insertBefore(p,r);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="capture identify alias people.set people.set_once set_config register register_once unregister opt_out_capturing has_opted_out_capturing opt_in_capturing reset isFeatureEnabled onFeatureFlags getFeatureFlag getFeatureFlagPayload reloadFeatureFlags group updateEarlyAccessFeatureEnrollment getEarlyAccessFeatures getActiveMatchingSurveys getSurveys onSessionId".split(" "),n=0;n<o.length;n++)g(u,o[n]);e._i.push([i,s,a])},e.__SV=1)}(document,window.posthog||[]);
			posthog.init('phc_fO1p5gLAQI3fxuUYeyAKx5mDoZ4hoZa3rV77vYDoMu',{api_host:'https://app.posthog.com'})
		</script>
	  	<script type="text/javascript">
		        ! function (o, c) {
		            var n = c.documentElement,
		                t = " w-mod-";
		            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
		        }(window, document);
		    </script>
  </head>
  <body>
    <h1
      id="ll"
      style="
        display: none;
        position: fixed;
        left: 20;
        top: 20;
        z-index: 2;
        color: white;
      "
    >
      adf
    </h1>

    <!-- <h1 id="ll" style="color: #fff;  position: fixed; left: 20; top: 20; z-index: 2;">fsdgdsfg</h1> -->
    <div
      id="loading"
      style="
        display: flex;
        height: 100%;
        width: 100%;
        padding-top: 4rem;
        align-items: start;
        justify-content: center;
        background: transparent;
        position: relative;
      "
    />
    <video
      id="video"
      playsinline
      webkit-playsinline
      width="360"
      height="360"
      loop
      style="display: none"
      crossorigin="anonymous"
      playsinline
    >
      Your browser does not support the video tag.
    </video>

    <script src="./third_party/three.js/three.js"></script>
    <script src="./third_party/three.js/GLTFLoader.js"></script>
    <script src="./third_party/three.js/VRControls.js"></script>
    <script src="./third_party/three.js/RGBELoader.js"></script>
    <script src="./third_party/three.js/PMREMGenerator.js"></script>
    <script src="./third_party/three.js/PMREMUVPacker.js"></script>
    <script src="./third_party/three.js/EquirectangularTocubeGenerator.js"></script>
    <script src="./three.ar.js"></script>
    <script>
      let initialTouchDistance = 0;
      let initialScale = 1;

      function handleTouchStart(event) {
        const touches = event.touches;
        // alert("hi")
        if (touches.length === 2) {
          // Calculate the initial distance between the two touches
          initialTouchDistance = Math.hypot(
            touches[0].pageX - touches[1].pageX,
            touches[0].pageY - touches[1].pageY
          );

          // Store the initial scale value
          initialScale = getScale();
        }
      }

      function handleTouchMove(event) {
        const touches = event.touches;

        if (touches.length === 2) {
          // Calculate the current distance between the two touches
          const currentTouchDistance = Math.hypot(
            touches[0].pageX - touches[1].pageX,
            touches[0].pageY - touches[1].pageY
          );

          // Calculate the scale factor based on the initial and current distances
          const scale =
            initialScale +
            (currentTouchDistance - initialTouchDistance) /
              (10000 * devicePixelRatio);

          // Apply the scale transformation to the content
          setScale(scale);
        }
      }

      function getScale() {
        return initialScale;
      }

      function setScale(scale) {
        initialScale = scale;
      }
    </script>

    <script>
      var vrDisplay;
      var vrControls;
      var arView;

      var canvas;
      var camera;
      var sound;
      var scene;
      var renderer;
      let cube;
      var cubes = [];
      var anchorManager;
      let mixer;
      var activeAction;
      var clock = new THREE.Clock();
      let arDebug;
      let glbUrl;
      let videoUrl = "";
      let videoTexture;
      let videoElement;
      var envMapTexture;
      var cubemap;
      let directionalLight;
      let scaleFromData = 1;
      var rotation = 0;
      var res;
      var colors = [
        new THREE.Color(0xffffff),
        new THREE.Color(0xffff00),
        new THREE.Color(0xff00ff),
        new THREE.Color(0xff0000),
        new THREE.Color(0x00ffff),
        new THREE.Color(0x00ff00),
        new THREE.Color(0x0000ff),
        new THREE.Color(0x000000),
      ];

      var BOX_SIZE = 0.2;

      function copyFunction() {
        // Create a temporary textarea element
        var tempTextArea = document.createElement('textarea');
        // Set its value to the current window's location href
        tempTextArea.value = window.location.href;
        // Append the textarea to the DOM
        document.body.appendChild(tempTextArea);
        // Select the text inside the textarea
        tempTextArea.select();
        // Execute the copy command
        document.execCommand('copy');
        // Remove the temporary textarea from the DOM
        document.body.removeChild(tempTextArea);

        alert('coppied link');
      }

      /**
       * Use the `getARDisplay()` utility to leverage the WebVR API
       * to see if there are any AR-capable WebVR VRDisplays. Returns
       * a valid display if found. Otherwise, display the unsupported
       * browser message.
       */
      THREE.ARUtils.getARDisplay().then(async function (display) {
        var loading = document.getElementById("loading");

        if (display) {
          loading.innerHTML = "loading...";
          vrDisplay = display;
          vrDisplay.resetPose();
          const url = new URL(window.location.href);

          // Get the search parameters from the URL
          const queryParams = url.searchParams;
          var param1 = queryParams.get("ide");
          if (param1 == null) param1 = 4;
          // alert(url);

          var assetURL =
            "https://us-central1-flam-central.cloudfunctions.net/rmbr-appclip-meta?asset_id=" +
            param1;
          var myHeaders = new Headers();
          myHeaders.append("accept", "*/*");
          var requestOptions = {
            method: "GET",
            headers: myHeaders,
          };

          // alert(assetURL);

          fetch(assetURL, requestOptions)
            .then(async (response) => {
              res = await response.json();
              try {
                if (res.meta.scale != null || res.meta.scale != undefined) {
                  scaleFromData = parseFloat(res.meta.scale);
                  initialScale = scaleFromData;
                }
              } catch {}

              init(res.url);
            })
            .then((result) => console.log(result))
            .catch((error) => console.log("error", error));
        } else {
          THREE.ARUtils.displayUnsupportedMessage();

          var isSafari = !!navigator.userAgent.match(
            /Version\/[\d\.]+.*Safari/
          );

          const ios = () => {
              if (typeof window === `undefined` || typeof navigator === `undefined`) return false;

              return /iPhone|iPad|iPod/i.test(navigator.userAgent || navigator.vendor || (window.opera && opera.toString() === `[object Opera]`));
          };

          if(ios()) {
		loading.innerHTML = `
		      <img
			  src="./card/arrow.png"
			  alt=""
			  style="position: absolute; top: 1rem; right: 3rem; height: 50px; object-fit: contain"
			/>
		      <div
			style="
			  display: flex;
			  flex-direction: column;
			  margin: 20px;
			  height: 218px;
			  border-radius: 16px;
			  border: 2px solid #0000001A;
			  background: #0000000D;
			  color: white;
			  align-items: center;
			  justify-content: start;
			  text-align: center;
			"
		      >
			<img
			  src="./card/play_iphone.png"
			  alt=""
			  style="height: 100%; width: 100%; object-fit: contain;"
			/>
			<i id="loadtext" style="
			  padding: 20px;
			  color: black;
			  font-size: 1.1rem;
			">Tap on “PLAY” to start your experience</i>
		      </div>
		`;
	  }

          if (!isSafari && ios()) {
            loading.innerHTML = `
              <div
                style="
                  display: flex;
                  flex-direction: row;
                  margin: 20px;
                  padding: 18px;
                  height: 140px;
                  border-radius: 16px;
                  border: 2px solid #0000001A;
                  background: #0000000D;
                  color: white;
                  align-items: center;
                  justify-content: between;
                  text-align: center;
                "
              >
                <div style="display: flex; flex-direction: column; justify-content: between;">
                  <p style="font-size: 16px; font-weight: 600; text-align: start; color: black;">Please open this link in Safari browser</p>
                  <button style="width: 100%; max-width: 60%; display: flex; align-items: center; justify-content: center; gap: 4px; background-color: #007AFF; outline: none; border: none; border-radius: 16px; padding: 0.5rem 1rem; color: white;" onclick="copyFunction()">
                    <svg width="14" height="16" viewBox="0 0 14 16" fill="none" xmlns="http://www.w3.org/2000/svg">
                      <path d="M9.99984 0.666664H1.99984C1.2665 0.666664 0.666504 1.26666 0.666504 2V11.3333H1.99984V2H9.99984V0.666664ZM11.9998 3.33333H4.6665C3.93317 3.33333 3.33317 3.93333 3.33317 4.66666V14C3.33317 14.7333 3.93317 15.3333 4.6665 15.3333H11.9998C12.7332 15.3333 13.3332 14.7333 13.3332 14V4.66666C13.3332 3.93333 12.7332 3.33333 11.9998 3.33333ZM11.9998 14H4.6665V4.66666H11.9998V14Z" fill="white"/>
                    </svg>
                    copy link
                  </button>
                </div>
                <img src="./card/safariImage.png" style="height: 80%; width: 80%; object-fit: contain;" />
              </div>
            `;
          }

	  const android = () => {
              if (typeof window === `undefined` || typeof navigator === `undefined`) return false;

              return /android/i.test(navigator.userAgent);
          };

	  if (!isSafari && android()) {
	    loading.innerHTML = ``;
	  }

        }
      });

      function init(
        glf = "https://storage.googleapis.com/rmbr/app_clip/Cop28_C.glb"
      ) {
        // Setup the three.js rendering environment
        renderer = new THREE.WebGLRenderer({ alpha: true });
        renderer.setPixelRatio(window.devicePixelRatio);
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.autoClear = false;
        renderer.toneMapping = THREE.ACESFilmicToneMapping;
        renderer.gammaInput = true;
        renderer.gammaOutput = true;
        canvas = renderer.domElement;
        canvas.addEventListener("touchstart", (addEventListener) => {
          handleTouchStart(event);
        });
        canvas.addEventListener("touchmove", (event) => {
          handleTouchMove(event);
          cube.scene.scale.set(initialScale, initialScale, initialScale);
        });
        document.body.appendChild(canvas);
        scene = new THREE.Scene();

        function rotateEnvMap(angle) {
          var rad = THREE.Math.degToRad(angle);

          var cubemapGenerator = new THREE.EquirectangularToCubeGenerator(
            envMapTexture,
            {
              resolution: 512,
              type: THREE.HalfFloatType,
              rotation: rad,
            }
          );

          var cubeMapTexture = cubemapGenerator.update(renderer);

          var pmremGenerator = new THREE.PMREMGenerator(cubeMapTexture);
          pmremGenerator.update(renderer);

          var pmremCubeUVPacker = new THREE.PMREMCubeUVPacker(
            pmremGenerator.cubeLods
          );
          pmremCubeUVPacker.update(renderer);

          var cubeRenderTarget = pmremCubeUVPacker.CubeUVRenderTarget;

          pmremGenerator.dispose();
          pmremCubeUVPacker.dispose();

          cubemap = cubeRenderTarget.texture;
        }

        var filepath =
          "https://storage.googleapis.com/rmbr/app_clip/brown_photostudio_02_1k.pic";
        if (res.meta.hdr != null || res.meta.hdr != undefined) {
          filepath = res.meta.hdr;
        }

        // document.getElementById('ll').innerHTML = filepath
        new THREE.RGBELoader().load(filepath, function (texture) {
          texture.minFilter = THREE.NearestFilter;
          texture.encoding = THREE.RGBEEncoding;
          texture.flipY = true;

          envMapTexture = texture;
          rotateEnvMap(rotation);
        });
        // Turn on the debugging panel
        arDebug = new THREE.ARDebug(vrDisplay, scene, { showPlanes: true });

        // document.body.appendChild(arDebug.getElement());

        // Creating the ARView, which is the object that handles
        // the rendering of the camera stream behind the three.js
        // scene
        arView = new THREE.ARView(vrDisplay, renderer);

        // The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera,
        // except when using an AR-capable browser, the camera uses
        // the projection matrix provided from the device, so that the
        // perspective camera's depth planes and field of view matches
        // the physical camera on the device.
        camera = new THREE.ARPerspectiveCamera(
          vrDisplay,
          60,
          window.innerWidth / window.innerHeight,
          vrDisplay.depthNear,
          1000
        );
        const listener = new THREE.AudioListener();

        if (res.meta.video != null || res.meta.video != undefined) {
          videoUrl = res.meta.video;
          videoElement = document.getElementById("video");
          videoElement.src = videoUrl;
          videoElement.autoplay = false;
          videoElement.loop = true;
          videoElement.muted = false;
          videoElement.style.display = "none";
          videoElement.crossorigin = "anonymous";
          videoElement.preload = "auto";

          videoTexture = new THREE.VideoTexture(videoElement);
          videoTexture.minFilter = THREE.LinearFilter;
          videoTexture.magFilter = THREE.LinearFilter;
          videoTexture.format = THREE.RGBFormat;
          videoTexture.mapping = THREE.UVMapping;
          videoTexture.flipY = false;
        }

        camera.add(listener);
        sound = new THREE.Audio(listener);

        try {
          if (res.meta.music != null || res.meta.music != undefined) {
            const audioLoader = new THREE.AudioLoader();
            audioLoader.load(res.meta.music, function (buffer) {
              sound.setBuffer(buffer);
              sound.setLoop(false);
              sound.setVolume(1);
              // sound.play()
            });
          }
        } catch {}

        // VRControls is a utility from three.js that applies the device's
        // orientation/position to the perspective camera, keeping our
        // real world and virtual world in sync.
        vrControls = new THREE.VRControls(camera);

        // Create the cube geometry and add it to the scene. Set the position
        // to (Infinity, Infinity, Infinity) so that it won't appear visible
        // until the first hit is found, and move it there
        var geometry = new THREE.BoxGeometry(BOX_SIZE, BOX_SIZE, BOX_SIZE);
        var faceIndices = ["a", "b", "c"];
        for (var i = 0; i < geometry.faces.length; i++) {
          var f = geometry.faces[i];
          for (var j = 0; j < 3; j++) {
            var vertexIndex = f[faceIndices[j]];
            f.vertexColors[j] = colors[vertexIndex];
          }
        }

        // Shift the cube geometry vertices upwards, so that the "pivot" of
        // the cube is at it's base. When the cube is added to the scene,
        // this will help make it appear to be sitting on top of the real-
        // world surface.
        // geometry.applyMatrix( new THREE.Matrix4().setTranslation( 0, BOX_SIZE / 2, 0 ) );
        geometry.translate(0, BOX_SIZE / 2, 0);
        var material = new THREE.MeshBasicMaterial({
          vertexColors: THREE.VertexColors,
        });
        cube = new THREE.Mesh(geometry, material);

        directionalLight = new THREE.DirectionalLight(0xffffff, 2);
        directionalLight.position.set(3, 0, 0);
        // scene.add( directionalLight );

        const light = new THREE.AmbientLight(0x404040, 2.0); // soft white light
        // scene.add( light )

        let loader = new THREE.GLTFLoader();

        loader.load(
          glf,
          function (gltf) {
            // alert("loader")
            cube = gltf;
            cube.scene.scale.set(scaleFromData, scaleFromData, scaleFromData);
            cube.scene.lookAt(camera.position);
            directionalLight.position = camera.position;

            // alert(JSON.stringify(gltf.scene.animations))
            var loading = document.getElementById("loading");
            loading.innerHTML = "Tap on Planes to place";

            update();
          },
          function (xhr) {
            // console.log( ( xhr.loaded / xhr.total * 100 ) + '% loaded' );
          },
          function (error) {
            // alert( JSON.stringify(error) );
          }
        );

        // Initialize the anchor manager
        anchorManager = new THREE.ARAnchorManager(vrDisplay);
        // Just show a message when anchors update.
        anchorManager.addEventListener("anchorsupdated", function (event) {
          // console.log(event.anchors.length + " Object3D-s updated their pose!");
        });

        // Bind our event handlers
        window.addEventListener("resize", onWindowResize, false);
        window.addEventListener("touchstart", onClick, false);

        // Kick off the render loop!
        // update();
      }

      /**
       * The render loop, called once per frame. Handles updating
       * our scene and rendering.
       */
      function update() {
        // alert("update")
        // Clears color from the frame before rendering the camera (arView) or scene.
        renderer.clearColor();

        // Render the device's camera stream on screen first of all.
        // It allows to get the right pose synchronized with the right frame.
        arView.render();

        // Update our camera projection matrix in the event that
        // the near or far planes have updated
        camera.updateProjectionMatrix();

        // Update our perspective camera's positioning
        vrControls.update();

        // Render our three.js virtual scene
        renderer.clearDepth();
        renderer.render(scene, camera);

        //play animations
        var delta = clock.getDelta();

        if (mixer) {
          mixer.update(delta);
        }

        // Kick off the requestAnimationFrame to call this function
        // when a new VRDisplay frame is rendered

        vrDisplay.requestAnimationFrame(update);
      }

      /**
       * On window resize, update the perspective camera's aspect ratio,
       * and call `updateProjectionMatrix` so that we can get the latest
       * projection matrix provided from the device
       */
      function onWindowResize() {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
      }

      /**
       * When clicking on the screen, fire a ray from where the user clicked
       * on the screen and if a hit is found, place a cube there.
       */
      function onClick(e) {
        if (cubes.length > 0) return;

        // Remove cubes with more than one finger.
        if (e.touches.length > 1 && cubes.length > 0) {
          scene.remove(cubes[0]);
          anchorManager.remove(cubes[0]);
          cubes.splice(0, 1);
          return;
        }

        arDebug.close();
        // Create a new cube and place it where the hit test specifies.
        var cubeClone = cube;

        //play animation

        // Inspect the event object and generate normalize screen coordinates
        // (between 0 and 1) for the screen position.
        var x = e.touches[0].pageX / window.innerWidth;
        var y = e.touches[0].pageY / window.innerHeight;

        // Send a ray from the point of click to the real world surface
        // and attempt to find a hit. `hitTest` returns an array of potential
        // hits.
        var hits = vrDisplay.hitTest(x, y);

        // If a hit is found, just use the first one
        if (hits && hits.length) {
          document.getElementById("loading").style.display = "none";
          mixer = new THREE.AnimationMixer(cubeClone.scene);
          // alert(JSON.stringify(cubeClone.animations))
          cubeClone.animationcs.forEach((clip) => {
            mixer.clipAction(clip).play();
          });
          sound.play();
          mixer.addEventListener("loop", function (e) {
            sound.stop();
            sound.play();
          });
          var hit = hits[0];
          // Use the `placeObjectAtHit` utility to position
          // the cube where the hit occurred
          THREE.ARUtils.placeObjectAtHit(
            cubeClone.scene, // The object to place
            hit, // The VRHit object to move the cube to
            1, // Easing value from 0 to 1; we want to move
            // the cube directly to the hit position
            true
          ); // Whether or not we also apply orientation
          directionalLight.target = cubeClone.scene;
          directionalLight.position = camera.position;
          cubeClone.scene.lookAt(
            new THREE.Vector3(
              camera.position.x,
              cubeClone.scene.position.y,
              camera.position.z
            )
          );
          anchorManager.add(cubeClone.scene);
          scene.add(cubeClone.scene);
          cubes.push(cubeClone.scene);

          // document.getElementById('ll').innerHTML =  'object'
          function setEnvironmentMap(object, texture) {
            // document.getElementById('ll').innerHTML =  object
            if (object.material) {
              // object.frustumCulled = false
              object.material.side = THREE.FrontSide;

              if (object.material.name == "Screen") {
                document.getElementById("ll").innerHTML = "Screen";
                object.material.emissiveMap = null;
                object.material.emissiveIntensity = 0;
                object.material.map = videoTexture;
              }

              if (Array.isArray(object.material)) {
                // Handle materials array
                object.material.forEach(function (material) {
                  material.envMap = texture;
                  material.needsUpdate = true;
                });
              } else {
                // Single material
                object.material.envMap = texture;
                object.material.needsUpdate = true;
              }
            }

            object.children.forEach(function (child) {
              setEnvironmentMap(child, texture);
            });
          }

          setEnvironmentMap(scene, cubemap);
          // videoElement.play();
        }
      }
    </script>
  </body>
</html>

